{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Week 11: Deployment, Monitoring & Reliability - SOLUTION\n\nComplete implementations for production deployment."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport logging\nimport time\n\napp = FastAPI(title='AI Service API', version='1.0.0')\n\nclass PredictionRequest(BaseModel):\n    input_data: dict\n\nclass PredictionResponse(BaseModel):\n    prediction: str\n    confidence: float\n    processing_time_ms: float\n\nclass AIModelService:\n    def __init__(self, model_path: str):\n        self.model_path = model_path\n        self.model = None\n        self.load_model()\n    \n    def load_model(self):\n        print(f'Loading model from {self.model_path}')\n        self.model = 'MockModel'\n    \n    def predict(self, input_data: dict) -> dict:\n        start_time = time.time()\n        prediction = 'Sample prediction'\n        confidence = 0.95\n        processing_time = (time.time() - start_time) * 1000\n        return {'prediction': prediction, 'confidence': confidence, 'processing_time_ms': processing_time}\n\nmodel_service = AIModelService('models/model.pkl')\n\n@app.get('/health')\nasync def health_check():\n    return {'status': 'healthy', 'model_loaded': True}\n\n@app.post('/v1/predict', response_model=PredictionResponse)\nasync def predict(request: PredictionRequest):\n    try:\n        result = model_service.predict(request.input_data)\n        return PredictionResponse(**result)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\nprint('FastAPI service configured and ready!')"]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
